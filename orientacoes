Orientação 20250909

Slide trabalhos relacionados - ao inves de mencionar os casos de estudo, listar os artigos utlizados no texto (uma lista com 5 itens - 1 p/ cada artigo) Nao precisa falar detalhadamente sobre cada, so mencionar que foram estudados. É para passar o sentimento de que "estão aqui os artigos". dar copy+paste do jeito que estão na bibliografia


Burocracias
1 - RPG -> enviar preenchido após receber a folha de assinaturas
2 - Monografia assinada (salvar a folha ii assinada à parte, e incluir posteriormente com um editor de pdf)
3 - Nada consta (Flavio gera, e me envia de volta)

Esses 3 documentos eu envio para o Teodosio


Rascunho

slide 4 - falar 1 frase para cntextualizar virtualizaçao e agentes/exportadores

sobre cada tópico - menciono apenas o que eu usei

virtualização - conceito de emular um sistema de forma virtual dentro de um sistema operacional host

escolhi o docker pois ele implementa a virtualização através de containers com arquivos de texto declarativo.

aproveitar o docker para falar de IaC, que permitiu praticidade, facil manutençao, replicabilidade e verisonamento

agentes - processos que rodam coletando métricas dentro de um sistema



slide 7 - explicar a nuvenzinha (um artifício visual para representar um rede virtual isolada)

slide 8 - ser mais conciso e objetivo na explicaçao (ficou um tanto longa)



Orientação 20250902

Fechar título

Definir nome para o repositório (baseado no título)

saturmon

Como deve ser a apresentação? Estrutura, roteiro, etc.

25 minutos para a apresentação do projeto, o resto são perguntas
Nao da pra falar de tudo em 25 minutos, mas vc pode detalhar respondendo uma pergunta

1 slide para tema
1 para objetivo
1 para Justificativa
tirar esses 3 da propria monografia - coloca 1 frase ou 1 topico do proprio capítulo 1 - os topicos sao para me lembrar, nao pode ficar mto verboso

fundamentação teorica - 2 ou 3 slides {

1 deles sobre os trabalhos relacionados
Os outros em condenso todo o restante do capitulo 2
}

Slides sobre o trabalho em si (caps 3 e 4){
 - 1 slide para cada diagrama (pula direto para o que foi feito, n precisa apresentar as versoes iniciais)
- Dashboard -> 2 slides - 1 para as seçoes (como está no texto) e +1 com a screenshot dos graficos de serie temporal

- Se souber encaixar, colocar 1 imagem do alerta do email 
}

Slides finais - 1 slide de consideraçoes finais e outro de trabalhos futuros

Sobre as figuras dos diagramas - nao se aprofundar, mas pontuar o quanto impactam nas tomadas de decisão - comentar sobre o que aconteceu, nao precisa falar como. Exemplo: historia dos bancos -> SQLite -> postgres -> tsdb. Relatar os fatos, o como deixo para as perguntas da banca


Orientação 20250826

Código Fonte 4.4 e 4.5 --> alteração da legenda para "pré" e "pós" normalização --> ok

Preciso de um título para o trabalho, e um nome para o repositorio do github (pode ser o mesmo do título do trabalho)?

Estava revisando o texto e notei que eu formatei todas as palavras estrangeiras em itálico (scraping, dashboard, host, etc.). No inpicio eu achei bom pela padronização, mas agora acho que ficou meio poluído visualmente. O que você acha?

exemplo -> swap memory em italico, mas swap nao
outro exemplo -> descartar todas as traduçoes de scraping, e usar apenas scraping em italico (todos as instancias)
fazer levantamento dos termos em italico, e enviar a lista para validação

OK - Discutir necessidade do gŕafico "network-cumulative" - acho que nao agrega valor ->> Pode manter

COmo um flavor adicional para a apresentaçaio - contar a historia dos leves travamentos/ ubuntu 20 x 24  disk I/O --> nao precisa escrever

Eu consigo exportar os gŕaficos em PNG pra adicioná-los ao texto, mas como tornar as informações legíveis se o texto ficará em preto e branco?

Pode por a imagem normal, colorida, sem problemas.

Figuras -> deixar em vermelho os novos blocos, com exceção da figura final, que pode ficar toda em preto.

Orientação 20250819

OK - Discussão sobre o termo "scraping" (3.2.3) 
---> usar o termo scraping em tudo

OK - Códigos recebem a categoria "Listing". Listing 3.1, Listing 3.2 Tá certo?
--->Trocar o termo "Listing" para "Listagem" ou "Código Fonte"


OK- {
Mudanças no load_simulator.sh: os testes estavam gerando travamentos na máquina. Rodava tudo ao mesmo tempo. Sem falar que por conta do while true sem checagens de kill, por vezes demorava 60 segundos para derrubar o container. Para isso, implementei checagens constantes para verificação de kill do container.Outro ponto é que estou implementando os testes indo de 1 device por vez (device1->device2...->device5 ->repete). Tudo isso precisa entrar na figura do fluxograma, ou posso apenas comentar no texto?  
---->Mantém a figura como está, reportando no texto as mudanças no script. Reportar também que as execuções dos testes aconteciam de forma assíncrona e simultânea, e agora serão executadas de forma síncrona e sequencial, para evitar travamentos na máquina..
}

OK{
Adição de apêndices para os códigos: quais as melhores práticas? Por tudo junto?  Dividir em vários apêndices temáticos? Se sim, quais seriam os temas? É um pouco complicado dividir em temas precisos visto que muitas vezes os códigos são complementares entre si.

---> No caso de uma citação, colocar no texto apenas uma parte ilustrativa do código fonte, e referenciar ao repositorio do Git. Não precisa ficar adicionando apêndices
}

Eu devo entrar em tecnicalidades das medições (isso é do escopo Telegraf e do Prometheus)? Critérios e técnicas utilizadas? Se sim, em que seção isso entra? E o quão detalhista eu deveria ser? Pois haveria discussões/observações em uma infinidade de detalhes que poderia inflar MUITO o texto.

---> Escrever no texto apenas os parametros de maior relevancia (parametros chave que poderia gerar falhas ou problemas), e explicar no texto de forma ilustrativa. Acrescentar na propria seão (telegraf.conf entra em agentes)


OK {
Discussão sobre as métricas: a explicação conceitual sobre as métricas é apresentada no Capítulo 2 subseção \ref{subsection:MetricasInteresse}. A única diferença é que no Cap 2 são apresentadas as métricas de interesse e suas respectivas descrições, enquanto no Cap 3 são apresentadas as métricas coletadas diretamente.

--->Tabela -> fazer uma texto explicando as medidas equivalentes, nao equivalentes 1:1 ou que nao sao obtidas (exemplo: o calculo de swap). A posiçao do texto, antes ou depois da tabela, dependerá do layout da pagina (onde encaixar melhor). Trocar o nome Métrica para Etiqueta, e traduzir o significado da metrica bruta coletada. Também adicionar as unidades de cada métrica bruta.
}

Discussão sobre 3.5 - está de acordo com os tópicos propostos? Acho que vai cobrir bem todo o trabalho executado, mas vai ficar grande demais para uma única seção.

---> Topicos estao bons. Virou um novo capitulo (cha04). Sobre a figura da stack final, ir referenciando cada parte do texto que corresponde aos blocos da figura. Vou apontando tal coisa foi dita na seção tal blablabla , agora so falta falar do alert mgr que sera discutido agora.

OK - 1.6 - Descrição: frases de 1 ou 2 linhas, resumem obejtivamente o que vai ser abordado em cada capítulo. Essas frases devem feitas num ÚNICO parágrafo.

Orientação 20250812

Os nomes dos blocos deveria estar em negrito? Não há necessidade

Eu não gosto da forma como representei o TSDB, pois ele dá a entender que o TSDB é "separado" do Prometheus, quando na verdade ele é parte intrínseca/interna do Prometheus server. Isso é preciosismo da minha parte?

--> Deixar o TSDB solto dentro do bloco do Prometheus

Dúvida: para os alertas, a seta vai do grafana para o alerta (Grafan->Alertas) ou sai do SQLite pros Alertas (SQLite->Alertas) ou ambos? Mesma dúvida para o Prometheus+TSDB+Alertmanager (ver imagem texto/prometheus_architecture.png)

--> A seta sai do grafana


Em que momento eu devo fala sobre as experiencias e alterações do SQLite pro Postgres? E subsequentemente da alteração para o TSDB? Pois eu passei o projeto todo usando o SQLite. Visto que só comecei a ter o problema do database lock lá pelo fim do projeto (alertas do grafana), talvez faça sentido estar na seção de aplicação. Mas ao mesmo tempo discorrer sobre isso agora, na seção 3.2, me permitiria matar a arquitetura inteira nesta seção.

Orientação 20250805

DÚVIDAS COM RELAÇÃO À ESTRUTURA DO TEXTO -> Eu escrevo o capítulo todo descrevendo a Metodologia ao mesmo tempo que realizo as Discussões para justificar as decisões;

Figuras e pilhas : Par figura pilha - 1 par para o que foi idealizado e 1 par para o que foi implementado. 2 pares para o momento 1(versao 1), 2 pares para o momento 2 (versao 2)

Adicionar o DB, pois todas as ferramentas puxam dele (zabbix, grafana, dahs, alertas)

Figura principal - fazer toda a figura completa com todas as implementações, mas nao apresentá-la de uma unica vez, apresentar por partes.

Figuras - nao usar as logos ou simbolos, usar apenas caixas pretas e brancas.

Seção 3.2 - paragrafo introdutorio e inicia com a figura do prometheus
após a figura, ir explicando como os blocos se comunicam.

Começar explicando os containers (quem sao e pra que estao ali)

Começar detalhando a historia dos agentes (começou com o node exporter, aí foi mudando ate o telegraf.

e detalhar melhor o bloco do prometheus (prom + tsdb)

falar do grafana

Orientação 20250729

  O notebook tem capacidade computacional mais elevado, mas tem restriçoes sobre o que pode ser instalado nele, sendo a principal restrição o sistema operacional, onde era obrigatório a utilização do ubuntu desktop 20.04. "Então eu mexi onde eu podia mexer"


  Devo explicar Git? nao, afinal é apenas um utilitario, como o VSCode. Nao é um personagem importante no projeto

  Onde incluir o repositório do projeto? Fazer referencia no texto

  Em que momentos eu devo inserir código? Alguma formatação específica?
  A partir da 3.2. Colocar trechos importantes de código. A cada trecho importante, referenciar um Apendice.
  Os Apendices deverao incluir o codigo completo dios scripts e arquivos YAML (seria como um backup leve do git)

Orientação 20250708

  1) Na seção 2.4.3 (Disco): deveria explicar/detalhar melhor o que são INODES? 
  
  nao precisa
  
  2) Na introdução da seção 2.4, a referencia para a documentação do kernel do linux já é o suficiente para todas as métricas? 
  
  nao, procurar referencias que expliquem de onde sairam essas metricas
  
  3) Posso alterar o nome da seção 2.5? De Auxiliadores para Sidecars? Não gostei do termo e também não o utilizei no texto. 
  
  Texto trocado para sidecars

  4) Como lidar com títulos de referencias muito grandes? Exemplo: referencias do github.

  Posso editar para algo curto e objetivo

  5) Na subseção 2.8.3, o qual eu falo do Grafana, eu deixo claro que ele suporta vários bancos de dados, mas não acho que ficou claro que ele tem um banco de dados interno para persistência de configurações, além das fontes de dados externas. Ficou meio vago, dando a entender que ele realmente só puxa dados de fontes externas e não tem persistência própria para algumas coisas.

  Nao precisa, está bom do jeito que está

  ###Dúvidas quanto às correções###

  1) Em 2.4.1 CPU, vc pede para eu remover a Observação. Devo então incluir em cada item da lista a unidade "%"?

  Colocar em cara item da lista

  2) Não sei bem que tipo de artigo/referência devo utilizar para as métricas de interesse.

  procurar referencias que expliquem de onde sairam essas metricas   
  
#################################
% ### Os comentarios abaixo vao para o cap3 ###

%!@@!#$@#$#@$@#$@
% A virtualização desempenha um papel essencial neste trabalho por dois motivos principais. Primeiramente, conforme discutido na Seção \ref{section:Delimitação}, a indisponibilidade de equipamentos motivou a adoção de técnicas de virtualização para simular diferentes dispositivos, permitindo a criação de um ambiente de testes controlado e replicável utilizando uma úniac máquina física como base. 

% Em segundo lugar, a conteinerização dos softwares de monitoramento e coleta de métricas contribui diretamente para a portabilidade, escalabilidade, automação e manutenção da solução desenvolvida. Ao encapsular os serviços em contêineres independentes, é possível garantir maior uniformidade entre ambientes de desenvolvimento e produção, além de alinhar a implementação aos princípios da IaC.
#################################

Orientação 20250701

Modificiar a formatação de citaçaõ para o padrao [1] (Padrao IEEE) (Manhatan)

  Discussões Iniciais do Capítulo 3:
    1) Abordagem Preliminar
    Qual OS? Rocky, Rasp OS, Ubuntu
    QUal hardware?NUC ou Raspberry
    Qual motor? Zabbix
    Qual interface? Zabbix UI ou Grafana?


    2) Descrição MACRO da Arquitetura da Solução
    Descrição da Arquitetura Final
    Apresentar os blocos gerais e explicar o que cada um faz, quais seus inputs e outputs, e como interagem entre si. 

    Um diagrama de blocos com a visao MACRO

    A ideia é que o leitor consigar ter um bom entendimento geral do projeto só com a seção 3.2   

    3) Infraestrutura
    As escolhas de OS, container, o que foi construido, como foi construido, aplicações a serem instaladas
    Falar o que instalou

    Fazer 1 subseção para cada bloco. Fazer no máximo 1 camada de subseção (3.2.1, 3.2.2, etc)

    4) Agentes (pode virar uma subseção de 3)

    5) Discussão sobre as métricas

    6) Aplicação de monitoramento
    Mostrar os comportamentos, desempenho/performance/problemas e correções, e escolha de graficos/usabilidade do dashboard, alertas e notificações



Orientação 20250624

  -> Ao mesmo tempo que acho que faltam imagens e diagramas nas explicações das ferramentas no capítulo 2, também acho que já tem muita coisa escrita, e ficaria muito massante com muita informação. Devo acrescentar ilustrações? Em todos os tópicos ou apenas em alguns selecionados? Não precisa de ilustrações no cap2
  -> Só deixar em caixa alta o que for sigla. 
  -> Em itálico somente um idioma estrangeiro. E quando for um nome próprio, nao precisa por em italico. Exemplo: Dockerfile nao precisa ser em italico
  -> Siglas precisam ser explicadas na lista de siglas e tambem na primeira vez que aparecem no texto.


Orientação 20250617

  - Praticamente traduzi as regras de alarmes e políticas de notificações dos ymls do Grafana para yml do Prometheus, levantei um container separado para o Alertmanager e configurei o Prometheus para enviar os alertas para o Alertmanager.
  - Tive dificuldade de fazer o Alertmanager rodar puxando a imagem direto do Docker Hub, pois é uma imagem bastante minimizada que estava com muitas dificuldades de lidar com referenciamento de variáveis dos arquivos .env. Como julgo uma medida de segurança importante (estaria, por exemplo, vazando a senha do smtp server do gmail), não quis deixar nada hardcoded e contornei o problema subindo um outro container Alpine e instalando o Alertmanager nele. Precisei criar um arquivo template para as configurações do Alertmanager e substituir as variáveis referenciadas em tempo de execução do docker compose utilizando um outro script que roda o comando envsubs via entrypoint do container. Se não tivesse ocorrido esse problema de referenciamento de variável, a integração com o Prometheus teria sido praticamente instantânea.
  - O Alertmanager é o serviço de alarmes oficial do Prometheus e ambos são muito otimizados para trabalhar juntos.

  -> Grafana + PostgreSQL versus Prometheus + Alertmanager; um resumo
    - Grafana+PostgreSQL foi fácil de configurar, mas não é tão performático e escalável quanto Prometheus+Alertmanager.
    
    - De forma geral, para projetos de alta performance (granularidades <30s e muita escrita concorrente) a opção definitiva é Prometheus+Alertmanager;

    - Para projetos menores, Grafana+PostgreSQL é suficientemente satisfatório.

    - Porém, não realizei estudos comparativos de utilização de recursos para melhor definir a que momento um passa a valer mais a pena que o outro em cada escopo.

  -> Esta experiência com o Alertmanager deve ser retratada no capítulo 3.

Orientação 20250610
  -> Capítulo 1 - Introdução, com as seguintes seções:

    - Tema
      - 1 linha para qual é o assunto que estou abordando
      - 1 linha sobre o problema que eu quero resolver

    - Delimitação
      - O que me impede de dar passos maiores? Limitadores do projeto. No meu caso, a indisponibilidade de usar dispositivos físicos para coleta de dados e ter de usar containers.
      - Outro limitador foi o fato de certas métricas estarem disponíveis apenas nos dispositivos físicos, como disk metrics. Algumas métricas não estariam disponiveis nos containers.

    - Justificativa
      - Por que? Por que o assunto é importante?

    - Objetivos
      - O que eu quero fazer? Qual o objetivo geral(o que eu quero fazer)?
      - Objetivos específicos (milestones):
        - Levantar as etapas principais do projeto, ir quebrando o projeto em pequenas etapas.
 
    - Metodologia
      - Como? Descreve como eu fiz a solução
      - Como eu chego nos objetivos/milestones?

    - Descrição
      - Seria um apontamento geral dos assuntos dos próximos capítulos

  -> Capítulo 2, com as seguintes seções:
    - Mencionar as ferramentas e técnicas existentes para monitoramento de containers, como Zabbix, Prometheus, Grafana, Telegraf, cAdvisor, Node Exporter, etc.
    - Agrupar as ferramentas em categorias, como:
      - Ferramentas de coleta de métricas
      - Ferramentas de visualização de métricas
      - Ferramentas de alerta e notificação

    - Lembrar que não são as minhas decisões de projeto, e sim sa ferramentas que existem no mercado e que são utilizadas para monitoramento.

    - Exemplo de seções:
    - Métricas de interesse
      - CPU
      - Memória
      - Disco
      - I/O
      - Rede
      - Processos
    - Ferramentas de coleta de métricas - Uma seção de "Agentes de monitoramento"
    - Framework scraping dos dados dos Agentes
      - Zabbix
      - Prometheus
    - Frameworks de visualização
    - Framework alertas/notificações de métricas
    - Trabalhos relacionados

    - O capítulo 2 é a fundamentação teórica do projeto, onde eu vou explicar as ferramentas que eu escolhi e por que eu escolhi elas.

  ->No fim das contas, optei por substituir o SQLite do Grafana pelo PostgreSQL, visto que os database locks estavam constantes e o Grafana chegou a crashar diversas vezes hoje (04/06/2025). Após migrar para o PostgreSQL (o que foi bem tranquilo), o problema foi definitivamente resolvido e o Grafana está com uma performance excelente. Aproveitei para voltar os alarmes para as configurações originais.
    Alert Type	  interval	evaluation_offset	relativeTimeRange	for
    Memory/Swap	  1m	        20s	                5m             5m
    CPU	          1m	        30s	                5m             5m
    Processes	    1m	        40s	                5m             5m
    Disk Space	  3m	        60s	                1h             20m
    Disk I/O	    3m	        60s	                5m             10m
  ->É importante escrever sobre essa experiência - que por conta das minhas escolhas de projeto (como usar o provisioning do Grafana e o TSDB do Prometheus), foi extremamente fácil migrar do SQLite para o PostgreSQL, e que essa migração resolveu os problemas de performance do Grafana.
Orientação 20250603
  -> Capítulo 1 - Introdução, com as seguintes seções:
    - Tema
      - 1 linha para qual é o assunto que estou abordando
      - 1 linha sobre o problema que eu quero resolver
    - Objetivos
      - O que eu quero fazer?
    - Metodologia
      - Como? Descreve como eu fiz a solução
    - Justificativa
      - Por que? Por que o assunto é importante?
    - Descrição
      - Seria um apontamento geral dos assuntos dos próximos capítulos

  -> Capítulo 2, com as seguintes seções:
    - Mencionar as ferramentas e técnicas existentes para monitoramento de containers, como Zabbix, Prometheus, Grafana, Telegraf, cAdvisor, Node Exporter, etc.
    - Agrupar as ferramentas em categorias, como:
      - Ferramentas de coleta de métricas
      - Ferramentas de visualização de métricas
      - Ferramentas de alerta e notificação

  -> Nerfei ainda mais os alarm rules numa tentativa de reduzir os erros de "max-retries-reached" do SQLite do Grafana., mas o gargalo ainda persiste. 
    - AlertStatesDataLayer
      Unexpected alert rules response
    - Experimentei remover completamente os alert rules e o problema desaparece. De fato as leituras concorrentes das queries do dashboard + queries do alert rules causam gargalos no SQLite do Grafana.
    -> POssível correção: o gargalo não é por conta das leituras concorrentes das queries do dashboard + queries do alert rules, mas sim pq enquanto as queries do dash rodam diretamente pelo TSDB do Prometheus, as queries dos alert rules rodam pelo SQLite do Grafana, que não lida bem com leituras concorrentes mais agressivas.

  -> fechar o network
      - Ficou faltando configurar alertas para packet drops e errors na rede, mas não consegui produzir dados com estas métricas. Como seguir?]--> Ter um melhor embasamento (tentar novamente seja para fazer funcionar, seja para justificar o pq nao funcionar)
      
    -> Abordagem
      - Introdução de uma ferramenta nova no stack -> um novo container rodando Iperf3, induzindo cargas de inbound e outbound nos containers linux. Com esta ferramenta consegui gerar tráfego de rede entre os containers, permitindo a coleta de métricas de inbound e outbound traffic.
        Nota-se que os valores de outbound são de ordem muito mais que os de inbound. Uma possível explicação é que os containers linux tem limitações de cpu e ram, o que pode limitar suas capacidades de processamento de pacotes. Na escrita do texto, ao mencionar este ponto, irei realizar e apresentar testes mais aprofundados, com o objetivo de validar ou refutar essa hipótese.
      ====#TODO====
      - Quanto aos network chaos tests: [relatar tentativas com pumba, chaosblade e iptables. Relatar que o inputs.net lê do path procfs/net/dev, que é um path que não é afetado por essas ferramentas de chaos engineering. 
          Pumba - não consegui nem fazer o pumba realizar os testes nos containers.
          Chaosblade - foi muito mais promissor, consegui rodar e conectar aos containers com facilidade. Aparentemente, ele estava realizando os testes com sucesso, mas não tive observabilidade destes testes, pois o Chaosblade usa a ferramenta "tc"+"netem" por debaixo dos panos para realizar os testes. Mais infos no pdf em /docs.
            No, there is no official Telegraf network plugin that can directly observe or report the effects of network chaos testing (such as packet loss, delay, or corruption) introduced by tools like tc netem, pumba, or chaosblade at the application or kernel queueing discipline (qdisc) level.
            Why?
            inputs.net and similar plugins (like inputs.system, inputs.docker, inputs.procstat) collect metrics from dev or Docker stats, which only reflect interface-level statistics (hardware/driver drops/errors), not software-induced chaos at the qdisc or firewall level.
            tc netem manipulates packets at the qdisc layer, and its effects are not reflected in dev counters.
          iptables - mesmo problema do tc netem.
          ]
      https://github.com/influxdata/telegraf/blob/master/plugins/inputs/net/README.md
      


-> fechar o disk

  -> Observei um erro de ~5% no gauge Disk Free host machine sdb2 (comparei com o disk manager do ubuntu). ---> Tentar obter essa métrica pelo terminal usando outros apps para fazer uma paridade. Obs: essas diferenças de espaço podem se dar ao permissionamento de pastas (permission denied)

  -Abordagem:
    1 - Como o inputs.disk do telegraf obtém estas métricas?
    O telegraf obtém estas métricas a partir do /proc filesystem
    https://github.com/influxdata/telegraf/blob/release-1.34/plugins/inputs/disk/README.md

    The used_percent field is calculated by used / (used + free) and not used / total as the unix df command does it. See wikipedia - df for more details.
    
    2 - A partir disso, que outros meios posso utilizar para ler tais métricas na mesma fonte do inputs.disk do telegraf?
      The "df" (disk free) command is the most reliable tool to check filesystem space usage on Unix/Linux systems.
    3 - Realizando a leitura das métricas a partir da mesma fonte e utilizando meios diferentes, houve disparidade nos dados obtidos?
      -------Cálculos corretos-------{
      {
        Rodando "df -h /dev/sdb2" no terminal:
        Filesystem                Size  Used Avail Use%
        Mounted on/dev/sdb2       234G  169G   53G  77% /

        Used% -> 100 * (Used / (Used + Free)) = 100 * (169 / (169 + 53)) = 100 * (169 / 222) = 100 * 0.76036036036 = 76.04%
        Free% -> 100 * (Free / (Used + Free)) = 100 * (53 / (169 + 53)) = 100 * (53 / 222) = 100 * 0.23873873873 = 23.87%
      }
      {
        Conferindo os valores do telegraf:
         Used -> 168.8 
         PromQL => (physical_disk_used{disk_partition="sdb2"} / (1024 * 1024 * 1024))

         Free -> 52.46
         PromQL => (physical_disk_free{disk_partition="sdb2"} / (1024 * 1024 * 1024))
        
        Used% = 100 * (168.8 / (168.8 + 52.46)) = 100 * (168.8 / 221.26) = 100 * 0.762 = 76.2%
        Free% = 100 * (52.46 / (168.8 + 52.46)) = 100 * (52.46 / 221.26) = 100 * 0.237 = 23.7%
      }
      {
        Valores presentes no app "Disks" do ubuntu
        Size - 256
        Free - 69
        72,9% Full
        Device /dev/sdb2
      }
      {
      Conclusão -> os valores de referência são os do "df -h". Ele não utiliza o espaço total em disco como denominador, mas sim a soma do espaço usado e do espaço livre. Essa abordagem é intencional e difere de simplesmente usar o total de blocos reportado, porque:

        O campo total reportado pelos sistemas de arquivos pode incluir blocos reservados para o superusuário (root) ou para metadados do sistema de arquivos, que não estão disponíveis para usuários comuns.

        A soma de usado + disponível reflete apenas os blocos que estão realmente acessíveis para usuários que não são root, fornecendo uma visão mais precisa do espaço utilizável.

      Ajustando a fórmula com os valores obtidos pelo inputs.disk do telegraf, chegamos a valores muito mais próximos do "df -h":
        df -h
        Used% = 76.04%
        Free% = 23.87%

        Telegraf
        Used% = 76.02%
        Free% = 23.7%

      Os valores obtidos pelo app Disks do ubuntu serão desconsiderados, pois utilizam outras bibliotecas e ferramentas, introduzindo outras distorções nos dados.
      }
      -------Cálculos errados-------{
        Rodando "df -h /dev/sdb2" no terminal:
        Filesystem                Size  Used Avail Use%
        Mounted on/dev/sdb2       234G  169G   53G  77% /

        Used% v1-> Fazendo Used/Size -> 169/234 * 100 = 72,222222222%. Um erro de ~5% do próprio Use% do "df"

        Free% v1-> Fazendo Avail/Size -> 53/234 * 100 = 22,64957265%.

        Used% v2-> Fazendo 100 - Free% v1 = 100 - 22,64957265% = 77,35042735%. Bate com o valor obtido do "df -h /dev/sdb2"

        Free% v2-> Fazendo 100 - Used% v1 = 100 - 72,222222222% = 27,777777778%. Diferença de ~5% do Free% v1


      }
      {
        Conferindo os valores do telegraf:
         Used% v1 -> {
         Used/Size -> 100 * 168.44/233.18 -> 72.23%
         PromQL => 100*(physical_disk_used{disk_partition="sdb2"} / physical_disk_total{disk_partition="sdb2"}) = 72.23%
         } -> bate com Used% v1 do "df -h /dev/sdb2"

         Free% v1 -> {
          Free/Size -> 100 * 52.82/233.18 -> 22,65%
          PromQL => 100*(physical_disk_free{disk_partition="sdb2"} / physical_disk_total{disk_partition="sdb2"}) = 22.65%
          } -> bate com Free% v1 do "df -h /dev/sdb2"
         }
      }
      {
        Valores presentes no app "Disks" do ubuntu
        Size - 256
        Free - 70
        72,8% Full
        Device /dev/sdb2
      }
      
      A única conclusão concreta que consigo tirar é que os valores do telegraf são coerentes, visto que são praticamente idênticos aos do "df -h /dev/sdb2". No entanto, não consigo chegar à uma conclusão sobre qual versão do cálculo de Used% e Free% é a mais correta.

Orientação 20250527

-> fechar o network
-> fechar o disk
-> refazer o capitulo 1
-> capitulo 2 -> scaffolding do capítulo-> levantamento dos fundamentos téoricos (embasamento superficial das ferramentas utilizadas no projeto. Pode falar do zabbix tbm, mas nao precisa dar tanto atençao a ele).


Fiz mais uma tentativa de adicionar um dispositivo Android no monitoramento. No caso, o meu celular. No entanto, tive muitos problemas de permissionamento do sistema. Se eu obtivesse um android rooteado, conseguiria facilmente realizar a aquisição de dados. No entanto, como não tenho acesso a um dispositivo rooteado, não consegui avançar nesse ponto. Aí entramos novamente na tentativa de simular um dispositivo Android rooteado na minha máquina, o que optamos por não fazer.
]--> Detalhar no texto minhas aventuras tentando incluir o Android no monitoramento, as dificuldades enfrentadas e a decisão de não prosseguir com a simulação de um dispositivo Android rooteado.

Alertas:
  - Configurei disparos via email (SMTP server do gmail) + Telegram (bot do telegram) (usando a UI do Grafana)
  - Quando tentei usar o provisioning/alerting do grafana, o Grafana parou de enviar notificações pelo Telegram (tem algum problema de parsing que causa o erro 400 Bad Request nas tentativas de envio de notificação. Eventualmente apareceu um 404 também. Acabei optando por ficar apenas com email)
  - Ou seja: se configurar pela UI, Telegram funciona. Se configurar via provisioning, não funciona. Pela UI teria de configurar manualmente em todo reset. Pelo provisioning tudo já sobe pré-configurado.
  - Configurei alertas para os seguintes eventos:
    - Se CPU, Memória ou Disk I/O Util tiverem uma média de uso acima de 85% por mais de 5 minutos, dispara um alerta. O Grafana coleta amostras a cada 10s(evaluation interval).
    - Se alguma partição do disco estiver com menos de 15% de espaço livre, dispara um alerta. Isso é verificado numa janela de tempo de 1 hora, com amostras a cada 30s.
    - Processos Zumbis - com amostras a cada 10s, se nos últimos 5 minutos houver mais de 10 processos zumbis, dispara um alerta.
    - Observei um erro de ~5% no gauge Disk Free host machine sdb2 (comparei com o disk manager do ubuntu). ---> Tentar obter essa métrica pelo terminal usando outros apps para fazer uma paridade. Obs: essas diferenças de espaço podem se dar ao permissionamento de pastas (permission denied)
    - Ficou faltando configurar alertas para packet drops e errors na rede, mas não consegui produzir dados com estas métricas. Como seguir?]--> Ter um melhor embasamento (tentar novamente seja para fazer funcionar, seja para justificar o pq nao funcionar)


  - Observação interessante: após adicionar todos os alertas, o SQLite do Grafana começou a apresentar erros de max-retries-reached. 
    {
      logger=context userId=0 orgId=0 uname= t=2025-05-27T12:27:52.177483761-03:00 level=error msg="Request Completed" method=GET path=/api/search status=500 remote_addr=172.18.0.1 time_ms=5011 duration=5.011170382s size=114 referer="http://localhost:3000/?from=now-6h&orgId=1&timezone=browser&to=now" handler=/api/search/ status_source=server errorReason=InternalError errorMessageID=sqlstore.max-retries-reached error="retry 1: database is locked"
    }
    - Eu assumi que isso tenha sido causado pela quantidades de api-requests. Aumentar o tempo de auto refresh do dashboard de 5s para 15s parece ter mitigado o problema, mas ele ainda existe. Mas uma coisa que achei curiosa foi o fato de que o erro só começou a acontecer depois que adicionei os alertas. Antes disso, o Grafana estava rodando bem com auto refresh de 5s. 
    - Parece que as configurações atuais já estão forçando o limite do SQLite quanto à escrita concorrente. Como seguir? Tentar otimizar os alertas? Realizar um estudo para melhora de performance da stack? Lembro que eu tinha achado o SQLite uma opção interessante pela leveza, mas visto esta situação, uma migração para o PostgreSQL talvez fosse interessante, mas não pretendo realizá-la neste projeto. Talvez acrescentar a sugestão posteriormente no texto?
    - De fato, o problema eram as leituras concorrentes agressivas dos alertas. Ao longo das adições das regras, fui percebendo que o Grafana vinha apresentando certa lentidão. Ao reduzir:
      - CPU evaluation interval de 10s para 30s
      - Memory e Processes evaluation interval de 10s para 1m
      - Disk evaluation interval de 30s para 1m
      - Redução de todos os maxDataPoints de 43200 para 1000
    O Grafana reduziu significantemente os erros de "Database locked, sleeping then retrying" error="database is locked" retry=1 code="database is locked"
    - Aparentemente, o SQLite não lida bem com leituras concorrentes mais agressivas, ficando a sugestão de que, para projetos maiores, o PostgreSQL seja uma opção mais interessante.
    - Após a introdução de offsets nos alarm rules, aparentemente o erro de "max-retries-reached" mitigado ainda mais, mas ainda persiste. Nota-se que se trata de um gargalo de concorrência do próprio SQLite. Voltei o auto refresh do dashboard para 5s e o Grafana está rodando bem.

Orientação 20250506

Consegui adicionar métricas de rede  e processos aos containers!!!

{1 - Atualizei a estratégia de coleta de métricas do Docker: agora estou utilizando o plugin inputs.docker diretamente no telegraf.conf do host. Dessa forma, o Telegraf coleta métricas diretamente do socket do Docker daemon (/var/run/docker.sock), garantindo maior precisão, já que os dados vêm da mesma fonte usada pelo próprio Docker para monitoramento. Com isso, obtenho métricas essenciais como uso de CPU, memória, disco (I/O) e rede. Esses dados podem ser usados para comparações qualitativas com as métricas coletadas por Telegrafs rodando dentro dos containers.

Mas fica a reflexão: faz sentido comparar métricas entre dispositivos virtuais? Quando o objetivo era comparar máquinas físicas versus containers, essa comparação qualitativa era justificável. Porém, ao comparar container versus container, será que essa análise ainda se sustenta? Há valor prático em comparar dispositivos virtuais entre si nesses termos?

--> Realmente não faz sentido, logo não é necessário fazer esse levantamento.
}
2 - Avaliar gráficos apresentados
  #2.1 - O quão "feio" é o fato de haver gráficos "Physical Hosts Only"? - NAO É FEIO, ESTÁ TUDO BEM
  #2.2 - Seria interessante calcular medias nos gráficos Time Series? Nao tem necessidade, pois ja temos muitos dados, poderia gerar poluição visual
  #2.3 - Gauge normal ou Bar Gauge? Gauge Normal
  #2.4 - No CPU Time Series - Normal ou Stacked? Normal
  #2.5 - Definir intervalos padrão de pontos nos gŕaficos (cpu e mem a cada 5s?) - Taxa de amostragem padrao do disco pode ser mais longa = 1m. Deixar a opção do usuario de escolher qual a taxa de amostragem (deixar opçoes como 5s, 15s ou 1m, 2m(disk), 5m(disk))
  #2.6 - Validações/Observações:
      ->CPU
        #-Virtual Hosts não tem Total Load ou Other Load (pois preciso da metrica "free" e containers nao tem. Eu ate poderia calcular mas aí teria de coletar varias outras metricas pra fazer um somatorio) - tá OK
        #- Bar Gauge ou Gauge normal? - Normal
      ->Mem
        #-Usar apenas o Bar Gauge pra diferenciar visualmente dos Gauges do CPU? - Normal
      ->Disk
        #-Time to Full Disk está meio errático - avaliar posteriormente no texto
        #-Disk usage de pizza é uma visualização muito ruim. Trocar por outra? Qual? Nao precisa trocar
      ->Disk I/O
        #-Ter um disclaimer que os Alpine devices não tem I/O metrics - Adicionado um comentário no row
        #-Gráficos de throughput continuam mostrando dados mesmo depois do disco ter sido unmount.-> Eles somem depois que passa a janela de tempo (ele mantém o last value quando para de vir dados mas ainda está dentro do timespan)
      ->Network
        -Dropped & Error Packets - qual a unidade deles?
        -Dropped & Error Packets sempre zerado... validar se está correto...
        -Responsividade para timespans não está muito boa?
        #-Bar Gauges Bugados - barras sempre preenchidas
        -Responsividade aos timespans?
        #-Virtual Hosts Network Inbound Traffic - dados pobres. Investir em outro simulador de carga?  - nao precisa, estao ok - validado com o físico
      ->Processes
      ->Trends Over Time
        #-CPU normal ou stacked? (mesmo problema da falta da métrica "free") - Normal
        -Network - Mesmos problemas da seção Network citados acima
  #2.7 - Validar $__intervals e $__ranges nas queries
  #2.8 - Permitir a seleção de múltiplas labels -> Usar CTRL+CLICK

#ok - p0 - montar o dash do grafana{
  if (comparações qualitativas container x container) != true{
    estrutura dashboard pronta?
    }
  else
    faltam as comparaçoes
}

#ok - 3 - Estou com dificuldadas para entender o sincronismo entre as marcações de tempo obtidas nos testes (docker logs) e os pontos nos gráficos. --> essa reflexao vale a pena acontecer no texto posteriormente


  #p2 - Configurar os stress tests de acordo com as diretrizes definidas (testes individuais e depois simultaneos) - estao funcionando perfeitamente na visao MACRO

----TO DO----
{
ok - Configurar smtp server para envio dos alertas por email
Configurar Alertas
--> fazer o log do banco do prometheus 1x por dia - quebrar em varios arquivos menores (diarios)
}

Orientação 20250429

  p0 - montar o dash do grafana - praticamente fechado, so fechar os ajustes finos

  p1 - Alarmes e Alertas

  p2 - Configurar os stress tests de acordo com as diretrizes definidas (testes individuais e depois simultaneos)

  p3(opcional) - estudo dos virtualizadores e tentar implementar o Raspberry + Telegraf (se der certo, segue para Android)


dashboard cockpit - deixar os gauges à mostra sempre, e os temporais minimzados

fazer o log do banco do prometheus 1x por dia - quebrar em varios arquivos menores (diarios)


Estou tentando evitar ao máximo configurações via interface, tentando fazer tudo "as code", por questões de aprendizagem, versionamento e robustez.
Por conta disso, estou tentando usar o Grafana VSCode extension para editar dashboards pelo proprio VSCode. Mas bati num erro:
Failed to save dashboard
<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <title>Error</title> </head> <body> <pre>Payload Too Large</pre> </body> </html>


O payload de dashboards muito grandes ultrapassa o limite de tamanho de payload da api do grafana ou extensao do vscode.

Toda e qualquer alteração feita via UI do Grafana é salva no grafana/config/grafana.db, uma base SQLite interna do grafana. Como isso fica num volume, há persistencia nos dados. Mas como são dados de runtime, não consigo versionar no git.

Orientação 20250415

OK -> Com as métricas físicas escolhidas, tentar obter as métricas mais equivalentes dos cgroups.(otimizar os outputs do prometheus)

OK -> Após definidas as métricas virtuais, analisar os dados obtidos no prometheus (otimização)

OK -> Fazer o mesmo para os docker metrics

??? -> Com os dados organizados, montar o dash no grafana.
        OK -> Será ajustado no Grafana (tem suporte nativo pra isso) - Ajustar Timezone das medidas
        OK -> Configurar volume do prometheus para persistencia de dados (importante escrever sobre as questões de permissão de escrita nos volumes)

Com o dash pronto, desenvolver melhor as limitações de hardware

disk

physical_disk_free
physical_disk_total
physical_disk_inodes_free

cpu
physical_cpu_usage_idle
physical_cpu_usage_iowait
physical_cpu_usage_system
physical_cpu_usage_user

disk i/o
physical_diskio_read_bytes
physical_diskio_write_bytes
physical_diskio_io_time
physical_diskio_io_util

memory
physical_mem_free
physical_mem_total
physical_mem_swap_free
physical_mem_swap_total

network
physical_net_bytes_recv
physical_net_bytes_sent
physical_net_drop_out
physical_net_drop_in
physical_net_err_in
physical_net_err_out

process
physical_processes_running
physical_processes_sleeping
physical_processes_total
physical_processes_zombies

Critério geral utilizado para escolher quais métricas usar -> o mais cross-platform possível. Exemplo: se uma métrica é específica para Linux, é descartada.

Physical device - tenho quais inputs vou usar, agora falta definir quais medidas vou usar

Virtual device - posso escolher varias coisas do cgroups, mas preciso escolher as medidas -> a dica é escolher medidas que façam overlap com o physical device

Orientação 20250408

Consegui atualizar o cgroups do note do trabalho para a v2, permitindo assim rodar meu projeto uniformemente em ambas as máquinas (pessoal e trabalho) -->importante ter uma observação sobre isso na escrita

p0 -> preciso analisar com mais calma, mas visto que consegui rodar meu projeto na máquina do trabalho, observei que NÃO tive esse problema de gaps nas medições - minha teoria é que meu desktop possa estar gargalando as medições.  --> investigar com mais profundidade (talvez derrubar alguns serviços para avaliar)

p1 e p2 - Ao invés de continuar lendo sobre quais métricas do cgroups são importantes para escolher quais usar, decidi ver primeiro quais métricas eu consigo a partir de um agente rodando num host real.
Para isso, botei o Telegraf rodando no notebook do trabalho (ubuntu 20). Problema - decidir qual plugin usar (aparentemente posso usar mais de 1 plugin pra coletar as mesmas métricas. Como escolher? Como não perder muito tempo validando melhor/pior escolha? No momento não tenho uma referência pra validação pra comparar quem é melhor ou pior.)
Estou analisando um por um por ver que métricas obtenho para ter uma ideia melhor

Orientação 20250401

1 - Tenho implementado meu projeto em 2 pcs - Note do trabalho (Ubuntu 20 cgroups v1) e Desktop pessoal (Ubuntu 24 cgroups v2). Essas diferenças de versoes nos cgroups acarreta em problemas de compatibilidade, e adaptar o projeto para lidar com ambas as versoes me preocupa por poder estar introduzindo mais distorções. Exemplo: não sei se o cgroups v1 e v2 lêem da mesma forma e obtém os mesmos dados.
--> isso é uma observaão importante de se ter quando explicicatar o processo de mediãção

2 - Estou lendo sobre o QEMU para simular o Raspberry. Dicas?
-> se ficar muito difícil, não fazer


-> a escolha atende à uma expectativa - Qual é a expectativa? Entao escolho para atender esta expectativa

Orientação 20250325

1 - perguntar dos agentes (telegraf, cAdvisor, node exporter) - quais situações usar -> usar telegraf pela isonomia (para evitar distorções)
2 - Quais stress tests são interessantes?
Performar todos (CPU, memória, disco, network) ao mesmo tempo ou separadamente? Qual a carga dos testes? -> primeiramente fazer testes individuais, e depois testes agregados com todos.
3 - terei de falar do zabbix na escrita, mas não tenho tanto embasamento pra justificar a troca. Só não estava confortável/gostando de usar. Não tenho algo muito técnico, não foi feito um estudo comparativo profundo.
->a usabilidade também é um fator. Se eu estava utilizando e não estava gostando da interface e ou usabilidade, isso é um custo a ser levado em conta